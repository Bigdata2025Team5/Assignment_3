{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SET MY_USER = CURRENT_USER();\n",
    "\n",
    "SET GITHUB_SECRET_USERNAME = 'Bigdata2025Team5';\n",
    "SET GITHUB_SECRET_PASSWORD = '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';\n",
    "SET GITHUB_URL_PREFIX = 'https://github.com/Bigdata2025Team5';\n",
    "SET GITHUB_REPO_ORIGIN = 'https://github.com/Bigdata2025Team5/Assignment_3.git';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2979125032.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    USE ROLE CO2_ROLE;\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "USE ROLE CO2_ROLE;\n",
    "USE WAREHOUSE CO2_WH;\n",
    "USE SCHEMA CO2_DB.INTEGRATIONS;\n",
    "\n",
    "EXECUTE IMMEDIATE FROM @DEMO_GIT_REPO/branches/main/scripts/deploy_notebooks.sql\n",
    "    USING (env => 'DEV', branch => 'dev');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "-- ----------------------------------------------------------------------------\n",
    "-- Create the account level objects (ACCOUNTADMIN part)\n",
    "-- ----------------------------------------------------------------------------\n",
    "\n",
    "USE ROLE ACCOUNTADMIN;\n",
    "\n",
    "-- Roles\n",
    "CREATE OR REPLACE ROLE CO2_ROLE;\n",
    "GRANT ROLE CO2_ROLE TO ROLE SYSADMIN;\n",
    "GRANT ROLE CO2_ROLE TO USER IDENTIFIER($MY_USER);\n",
    "\n",
    "GRANT CREATE INTEGRATION ON ACCOUNT TO ROLE CO2_ROLE;\n",
    "GRANT EXECUTE TASK ON ACCOUNT TO ROLE CO2_ROLE;\n",
    "GRANT EXECUTE MANAGED TASK ON ACCOUNT TO ROLE CO2_ROLE;\n",
    "GRANT MONITOR EXECUTION ON ACCOUNT TO ROLE CO2_ROLE;\n",
    "GRANT IMPORTED PRIVILEGES ON DATABASE SNOWFLAKE TO ROLE CO2_ROLE;\n",
    "\n",
    "-- Databases\n",
    "CREATE OR REPLACE DATABASE CO2_DB;\n",
    "GRANT OWNERSHIP ON DATABASE CO2_DB TO ROLE CO2_ROLE;\n",
    "\n",
    "-- Warehouses\n",
    "CREATE OR REPLACE WAREHOUSE CO2_WH WAREHOUSE_SIZE = XSMALL, AUTO_SUSPEND = 300, AUTO_RESUME= TRUE;\n",
    "GRANT OWNERSHIP ON WAREHOUSE CO2_WH TO ROLE CO2_ROLE;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- ----------------------------------------------------------------------------\n",
    "-- Create the database level objects\n",
    "-- ----------------------------------------------------------------------------\n",
    "USE ROLE CO2_ROLE;\n",
    "USE WAREHOUSE CO2_WH;\n",
    "USE DATABASE CO2_DB;\n",
    "\n",
    "-- Schemas\n",
    "CREATE OR REPLACE SCHEMA INTEGRATIONS;\n",
    "CREATE OR REPLACE SCHEMA RAW_CO2;\n",
    "CREATE OR REPLACE SCHEMA Harmonized_CO2;\n",
    "CREATE OR REPLACE SCHEMA Analytics_CO2;\n",
    "\n",
    "CREATE OR REPLACE SCHEMA DEV_SCHEMA;\n",
    "CREATE OR REPLACE SCHEMA PROD_SCHEMA;\n",
    "\n",
    "\n",
    "\n",
    "CREATE OR REPLACE STAGE RAW_CO2.CO2_EXTERNAL_STAGE  \n",
    "URL = 's3://bigdata2025assignment3/co2_daily.csv'\n",
    "CREDENTIALS = (AWS_KEY_ID = 'AKIAZPPGAAEKCP7YN7TM' \n",
    "AWS_SECRET_KEY = '7vERWy3Zl/Gec2xRcJuIJ8rCCyJip9PuJrWqQQCe');\n",
    " \n",
    "-- Secrets (schema level)\n",
    "CREATE OR REPLACE SECRET DEMO_GITHUB_SECRET\n",
    "  TYPE = password\n",
    "  USERNAME = $GITHUB_SECRET_USERNAME\n",
    "  PASSWORD = $GITHUB_SECRET_PASSWORD;\n",
    "/*\n",
    "-- API Integration (account level)\n",
    "USE ROLE ACCOUNTADMIN;\n",
    "\n",
    "CREATE OR REPLACE API INTEGRATION DEMO_GITHUB_API_INTEGRATION\n",
    "  API_PROVIDER = GIT_HTTPS_API\n",
    "  API_ALLOWED_PREFIXES = ($GITHUB_URL_PREFIX)\n",
    "  ALLOWED_AUTHENTICATION_SECRETS = (DEMO_GITHUB_SECRET)\n",
    "  ENABLED = TRUE;\n",
    "\n",
    "-- Git Repository\n",
    "CREATE OR REPLACE GIT REPOSITORY DEMO_GIT_REPO\n",
    "  API_INTEGRATION = DEMO_GITHUB_API_INTEGRATION\n",
    "  GIT_CREDENTIALS = DEMO_GITHUB_SECRET\n",
    "  ORIGIN = $GITHUB_REPO_ORIGIN;\n",
    "\n",
    "*/\n",
    "CREATE OR REPLACE TABLE RAW_CO2.Daily_Measurements (\n",
    "date STRING ,\n",
    "co2_ppm FLOAT);\n",
    "\n",
    "COPY INTO RAW_CO2.Daily_Measurements\n",
    "    FROM @RAW_CO2.CO2_EXTERNAL_STAGE\n",
    "    FILE_FORMAT = (\n",
    "        TYPE = CSV \n",
    "        SKIP_HEADER = 1\n",
    "        FIELD_OPTIONALLY_ENCLOSED_BY = '\"'\n",
    "    )\n",
    "    ON_ERROR = CONTINUE;\n",
    "\n",
    "CREATE OR REPLACE STREAM RAW_CO2.DAILY_MEASUREMENTS_STREAM ON TABLE RAW_CO2.DAILY_MEASUREMENTS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "USE ROLE ACCOUNTADMIN;\n",
    "\n",
    "CREATE EVENT TABLE CO2_DB.INTEGRATIONS.DEMO_EVENTS;\n",
    "GRANT SELECT ON EVENT TABLE CO2_DB.INTEGRATIONS.DEMO_EVENTS TO ROLE CO2_ROLE;\n",
    "GRANT INSERT ON EVENT TABLE CO2_DB.INTEGRATIONS.DEMO_EVENTS TO ROLE CO2_ROLE;\n",
    "\n",
    "ALTER ACCOUNT SET EVENT_TABLE = CO2_DB.INTEGRATIONS.DEMO_EVENTS;\n",
    "ALTER DATABASE CO2_DB SET LOG_LEVEL = INFO;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, to_date, avg\n",
    "from snowflake.snowpark.window import Window\n",
    " \n",
    "# Function to transform CO2 data\n",
    "def transform_co2_data(session):\n",
    "    try:\n",
    "        # 1. Read data from the raw table\n",
    "        raw_df = session.table(\"CO2_DB.RAW_CO2.DAILY_MEASUREMENTS\")\n",
    " \n",
    "        # 2. Apply transformations\n",
    "        harmonized_df = raw_df.select(\n",
    "            to_date(col(\"DATE\")).alias(\"DATE\"),  # Convert the DATE column to a DATE type\n",
    "            col(\"CO2_PPM\").cast(\"float\").alias(\"CO2_PPM\")  # Cast CO2_PPM to float\n",
    "        )\n",
    " \n",
    "        # 3. Remove any rows with null values (optional, but good practice)\n",
    "        harmonized_df = harmonized_df.na.drop()\n",
    " \n",
    "        # 4. Calculate a 7-day rolling average (optional, but adds value)\n",
    "        window = Window.orderBy(col(\"DATE\")).rowsBetween(-6, 0)\n",
    "        harmonized_df = harmonized_df.with_column(\n",
    "            \"ROLLING_7DAY_AVG\",\n",
    "            avg(col(\"CO2_PPM\")).over(window)\n",
    "        )\n",
    " \n",
    "        # 5. Write the transformed data to the harmonized table\n",
    "        harmonized_df.write.mode(\"overwrite\").save_as_table(\"CO2_DB.HARMONIZED_CO2.CO2_EMISSIONS_HARMONIZED\")\n",
    " \n",
    "        print(\"Data transformation completed successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Transformation failed: {e}\")\n",
    "        raise  # Re-raise the exception for the notebook to display\n",
    " \n",
    "# Create a Snowpark session\n",
    "try:\n",
    "    # Snowflake Notebooks automatically use the current session for authentication.\n",
    "    # No need to manually create a session or provide credentials.\n",
    "    session = Session.builder.appName(\"CO2_Data_Transformation\").getOrCreate()\n",
    "    print(\"Snowflake session established.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating Snowpark session: {e}\")\n",
    "    raise  # Re-raise so notebook shows the error\n",
    " \n",
    "# Run the transformation\n",
    "try:\n",
    "    transform_co2_data(session)\n",
    "    print(\"Transformation completed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Transformation failed: {e}\")\n",
    "    raise  # Re-raise the exception for the notebook to display\n",
    " \n",
    "# Close the session\n",
    "finally:\n",
    "    if 'session' in locals():  # Check if session was created before closing\n",
    "        session.close()\n",
    "        print(\"Snowflake session closed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, lag, when\n",
    "from snowflake.snowpark.window import Window\n",
    " \n",
    "def calculate_co2_percentage_change(session: Session):\n",
    "    \"\"\"Calculates the percentage change in CO2_PPM from the previous day.\"\"\"\n",
    "    # Access the harmonized table\n",
    "    harmonized_df = session.table(\"CO2_DB.HARMONIZED_CO2.CO2_EMISSIONS_HARMONIZED\")\n",
    " \n",
    "    # Create a window specification ordered by 'DATE'\n",
    "    window_spec = Window.orderBy(col(\"DATE\"))\n",
    " \n",
    "    # Calculate the previous CO2_PPM value using lag function\n",
    "    harmonized_df = harmonized_df.with_column(\n",
    "        \"PREVIOUS_CO2\", lag(col(\"CO2_PPM\")).over(window_spec)\n",
    "    )\n",
    " \n",
    "    # Calculate the percentage change from the previous day\n",
    "    harmonized_df = harmonized_df.with_column(\n",
    "        \"PERCENTAGE_CHANGE\",\n",
    "        when(col(\"PREVIOUS_CO2\").isNotNull(),\n",
    "             ((col(\"CO2_PPM\") - col(\"PREVIOUS_CO2\")) / col(\"PREVIOUS_CO2\")) * 100\n",
    "        ).otherwise(None)\n",
    "    )\n",
    " \n",
    "    # Show the result (this should display the dataframe in Snowflake Notebooks)\n",
    "    harmonized_df.show()\n",
    " \n",
    "    # Optionally, if you want to save the results back to the table:\n",
    "    harmonized_df.write.mode(\"overwrite\").save_as_table(\"CO2_DB.HARMONIZED_CO2.CO2_EMISSIONS_HARMONIZED_WITH_PERCENTAGE_CHANGE\")\n",
    " \n",
    "    # Return the dataframe (or if you want to keep working with it)\n",
    "    return harmonized_df\n",
    " \n",
    "# Call the function\n",
    "harmonized_df_with_percentage_change = calculate_co2_percentage_change(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE FUNCTION CO2_DB.HARMONIZED_CO2.CALCULATE_SEASONAL_VARIATION()\n",
    "RETURNS TABLE (\n",
    "    MONTH INT,\n",
    "    AVG_CO2_PPM FLOAT,\n",
    "    DEVIATION_FROM_ANNUAL_MEAN FLOAT\n",
    ")\n",
    "AS\n",
    "$$\n",
    "    WITH annual_mean AS (\n",
    "        SELECT AVG(CO2_PPM) AS mean\n",
    "        FROM CO2_DB.HARMONIZED_CO2.CO2_EMISSIONS_HARMONIZED\n",
    "    ),\n",
    "    monthly_avg AS (\n",
    "        SELECT \n",
    "            EXTRACT(MONTH FROM DATE)::INT AS MONTH,\n",
    "            AVG(CO2_PPM) AS AVG_CO2_PPM\n",
    "        FROM CO2_DB.HARMONIZED_CO2.CO2_EMISSIONS_HARMONIZED\n",
    "        GROUP BY EXTRACT(MONTH FROM DATE)\n",
    "    )\n",
    "    SELECT \n",
    "        m.MONTH,\n",
    "        m.AVG_CO2_PPM,\n",
    "        m.AVG_CO2_PPM - a.mean AS DEVIATION_FROM_ANNUAL_MEAN\n",
    "    FROM monthly_avg m, annual_mean a\n",
    "    ORDER BY m.MONTH\n",
    "$$;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM TABLE(CO2_DB.HARMONIZED_CO2.CALCULATE_SEASONAL_VARIATION());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, date_trunc, avg, sum\n",
    "\n",
    "# Create a Snowpark session\n",
    "\n",
    "def create_daily_metrics_table(session):\n",
    "    \"\"\"Creates a daily performance metrics table for CO2 levels.\"\"\"\n",
    "\n",
    "    # Fully qualify the source table with the database and schema\n",
    "    qualified_source_table = \"CO2_DB.HARMONIZED_CO2.CO2_EMISSIONS_HARMONIZED\"\n",
    "\n",
    "    # Load the data from the source table (fully qualified)\n",
    "    df = session.table(qualified_source_table)\n",
    "\n",
    "    # Aggregate the data by day, calculating the average and sum of CO2_PPM\n",
    "    daily_metrics = df.groupBy(date_trunc('day', col(\"DATE\")).alias(\"DAILY_DATE\")) \\\n",
    "                       .agg(avg(\"CO2_PPM\").alias(\"AVG_CO2_PPM\"), \\\n",
    "                            sum(\"CO2_PPM\").alias(\"SUM_CO2_PPM\"))\n",
    "\n",
    "    # Fully qualify the target table with the database and schema\n",
    "    qualified_target_table = \"CO2_DB.ANALYTICS_CO2.daily_co2_metrics\"\n",
    "\n",
    "    # Write the resulting daily metrics to the target table\n",
    "    daily_metrics.write.mode(\"overwrite\").save_as_table(qualified_target_table)\n",
    "\n",
    "    # Print a confirmation message\n",
    "    print(f\"Daily CO2 metrics table created: {qualified_target_table}\")\n",
    "\n",
    "# Call the function with the created session\n",
    "create_daily_metrics_table(session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##weekly metric table:\n",
    " \n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, date_trunc, avg, sum\n",
    " \n",
    "def create_weekly_metrics_table(session: Session):\n",
    "    \"\"\"Creates a weekly performance metrics table for CO2 levels.\"\"\"\n",
    " \n",
    "    # Fully qualify the source table with the database and schema\n",
    "    qualified_source_table = f\"CO2_DB.HARMONIZED_CO2.CO2_EMISSIONS_HARMONIZED\"\n",
    " \n",
    "    # Load the data from the source table (fully qualified)\n",
    "    df = session.table(qualified_source_table)\n",
    " \n",
    "    # Aggregate the data by week, calculating the average and sum of CO2_PPM\n",
    "    weekly_metrics = df.groupBy(date_trunc('week', col(\"DATE\")).alias(\"WEEKLY_DATE\")) \\\n",
    "                        .agg(avg(\"CO2_PPM\").alias(\"AVG_CO2_PPM\"), \\\n",
    "                             sum(\"CO2_PPM\").alias(\"SUM_CO2_PPM\"))\n",
    " \n",
    "    # Fully qualify the target table with the database and schema\n",
    "    qualified_target_table = f\"CO2_DB.ANALYTICS_CO2.weekly_co2_metrics\"  # You can change the target table name here\n",
    " \n",
    "    # Write the resulting weekly metrics to the target table\n",
    "    weekly_metrics.write.mode(\"overwrite\").save_as_table(qualified_target_table)\n",
    " \n",
    "    # Print a confirmation message\n",
    "    print(f\"Weekly metrics table created: {qualified_target_table}\")\n",
    "\n",
    "create_weekly_metrics_table(session)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
